% ----------------------------------------------------------
% Introdução 
% Capítulo sem numeração, mas presente no Sumário
% ----------------------------------------------------------

\chapter[Fundamentação Teórica]{Fundamentação Teórica}




\section{Colinearidade}\label{sec:colineariedade}

Colinearidade, também chamada de multicolinearidade, ocorre quando duas ou mais variáveis preditoras de um conjunto de dados apresentam uma relação linear \cite{Carsten2012Collinearity}, ou seja, é possível expressar uma variável como combinação linear de outra. Esse problema afeta diversos algoritmos amplamente utilizados em aprendizado de máquina, como Regressão Linear e Regressão Logística, além de impactar técnicas de Inteligência Artificial Explicável (XAI) \cite{salih2025a_perpective}.

Um indicador simples e frequentemente utilizado para detectar colinearidade é a correlação de Pearson entre variáveis preditoras. O coeficiente de Pearson ($r$) mede o grau de associação linear entre duas variáveis, variando de $-1$ a 1: valores próximos de 1 indicam forte correlação positiva; valores próximos de $-1$ indicam forte correlação negativa; e valores próximos de 0 indicam ausência de associação linear \cite{PearsonCorrelationCoefficient}. Quanto maior o valor absoluto de $r$, maior é a dependência linear entre as variáveis, sugerindo a presença de colinearidade. \citeonline{Carsten2012Collinearity} recomenda o limiar $|r| \geq 0{,}7$ como indicativo de quando a colinearidade começa a distorcer de forma significativa as estimativas dos modelos.

%\section{Inteligência Artificial Explicável}\label{sec:xai}
%\lipsum[35]

%\subsection{SHAP}
%\lipsum[35]

%\subsection{LIME}
%\lipsum[35]

%\section{Algoritmos de Classificação}\label{sec:alg_class}
%\lipsum[35]
%\section {Problemas de classificação}
%\subsection{Algoritmos utilizados em problemas de classificação}\label{sec:algoritmos_classificacao}

%\section{Inteligência Artificial Explicável (XAI)}

%\subsection{Algoritmos de XAI}\label{sec:algoritmos_xai}

\section{Trabalhos relacionados}\label{sec:trabalhos_relacionados}

Alguns trabalhos foram desenvolvidos com o objetivo de compreender e mitigar os efeitos da colinearidade nos algoritmos de Inteligência Artificial Explicável (XAI). \citeonline{Basu2022Multicollinearity} apresentaram um framework matemático para corrigir a multicolinearidade no cálculo de valores de Shapley. Eles argumentam que a versão tradicional do SHAP assume independência entre atributos, o que não é realista e pode distorcer a atribuição de importância. Para resolver isso, propuseram um ajuste matricial que corrige os valores de Shapley considerando as correlações entre as variáveis, de modo que a importância individual se torne independente da multicolinearidade. Além disso, estenderam essa correção para calcular efeitos combinados de pares (ou grupos) de variáveis correlacionadas, somando os valores ajustados. O método foi validado em problemas reais de classificação, demonstrando boa eficiência computacional e explicações mais consistentes em presença de variáveis correlacionadas.

Dando continuidade à discussão sobre os impactos da multicolinearidade na explicabilidade, \citeonline{Salih2022Investigating} propuseram um novo critério de estabilidade para avaliar técnicas de XAI aplicadas à classificação de demência com base em imagens de ressonância magnética. Os autores treinaram modelos de classificação para diferenciar pacientes com e sem demência e analisaram a robustez dos rankings de importância gerados por métodos explicativos. A principal contribuição foi o desenvolvimento do NMR (\textit{Normalized Movement Rate}), um critério que quantifica a estabilidade das explicações fornecidas por técnicas de XAI, especialmente em cenários com multicolinearidade entre atributos. Os resultados demonstraram que o NMR melhora a confiabilidade na identificação de variáveis informativas, contribuindo para uma personalização mais segura do monitoramento clínico.

A partir da mesma motivação, \citeonline{Salih2024Characterizing} apresentaram o método \textit{Modified Index Position} (MIP) como uma solução simples e agnóstica ao modelo para ajustar os rankings de importância de variáveis gerados por métodos de XAI, como o SHAP, especialmente em contextos com colinearidade entre atributos. A abordagem consiste em remover iterativamente a variável mais importante apontada pela técnica de XAI, retreinar o modelo e reaplicar a explicabilidade, observando como as demais variáveis mudam de posição no ranking. Isso permite reordenar a importância original de forma a refletir dependências entre as variáveis. Aplicado a uma tarefa de classificação de gênero (homem ou mulher) com base em nove fenótipos cardíacos, o método demonstrou rankings mais robustos e menos sensíveis à colinearidade em comparação ao SHAP tradicional, sendo validado por análise de componentes principais e plausibilidade biológica.

Complementando esse estudo, \citeonline{salih2025a_perpective} investigaram as limitações dos métodos SHAP e LIME ao aplicá-los separadamente em dois conjuntos de dados distintos. Em cada experimento, treinaram quatro modelos de classificação (LightGBM, Regressão Logística, Árvore de Decisão e SVC) e analisaram como cada variável era explicada por cada modelo. Os resultados mostraram que ambos os métodos apresentaram forte dependência do modelo, com variações na ordem e na direção da contribuição das variáveis em cada classificador. Além disso, a presença de colinearidade comprometeu a interpretação, já que variáveis correlacionadas recebiam baixa importância por serem explicadas por outras. Para mitigar esses efeitos, os autores propuseram o uso da métrica NMR para avaliar a estabilidade das explicações entre os modelos e o método MIP para ajustar a importância das variáveis considerando a multicolinearidade. 

Explorando outra abordagem para lidar com esse desafio, \citeonline{Salih2025AdditiveEffects} propôs o método \textit{Additive Effects of Collinearity (AEC)} para superar as limitações de métodos de XAI em contextos com colinearidade entre variáveis. O autor argumenta que técnicas como o SHAP e LIME assumem independência entre os atributos, o que pode distorcer os rankings de importância. O AEC contorna esse problema ao decompor modelos multivariáveis em modelos univariáveis, estimando o efeito isolado de cada variável e, depois, somando esses efeitos considerando suas interdependências. O método foi validado em tarefas de regressão e classificação com dados simulados e reais, utilizando regressão logística e regressão linear. A partir das explicações geradas, o autor utilizou a métrica NMR para avaliar o impacto da colinearidade, concluindo que o AEC é mais robusto e estável do que o SHAP tradicional.

Por fim, \citeonline{Salih2024MiniReview} realizou uma revisão sistemática da literatura para investigar como as técnicas de Inteligência Artificial Explicável (XAI) lidam com a multicolinearidade entre variáveis. Após filtrar artigos das bases Web of Science, Scopus e IEEE Xplore, foram identificadas apenas sete abordagens que tratam explicitamente esse problema. Os autores destacam que não existe, até o momento, uma técnica de XAI que por natureza mitigue o impacto da dependência entre atributos. Além disso, observam que as soluções existentes são limitadas: ou adaptadas para métodos específicos (como o SHAP), ou restritas a explicações locais, concluindo que são necessários avanços metodológicos que considerem interações complexas entre atributos correlacionados, tanto na geração quanto na visualização das explicações.



%\section{Considerações Finais}\label{sec:fund_consideracoes_finais}
%\lipsum[35]

